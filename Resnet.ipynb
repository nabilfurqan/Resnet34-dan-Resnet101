{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3693,"status":"ok","timestamp":1660707049642,"user":{"displayName":"nabil furqan","userId":"03747923580904763607"},"user_tz":-420},"id":"3Xre-WAfBXuu"},"outputs":[],"source":["# Library yang digunakan\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import os\n","import time\n","import copy\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10995,"status":"ok","timestamp":1660650527960,"user":{"displayName":"nabil furqan","userId":"03747923580904763607"},"user_tz":-420},"id":"S7IEFT4GBxgB","outputId":"3fd791de-aa3e-49ff-8491-636d1fcbde17"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyunpack in /usr/local/lib/python3.7/dist-packages (0.3)\n","Requirement already satisfied: easyprocess in /usr/local/lib/python3.7/dist-packages (from pyunpack) (1.1)\n","Requirement already satisfied: entrypoint2 in /usr/local/lib/python3.7/dist-packages (from pyunpack) (1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: patool in /usr/local/lib/python3.7/dist-packages (1.12)\n"]}],"source":["#menghubungkan ke gdrive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install pyunpack\n","!pip install patool\n","\n","from pyunpack import Archive\n","Archive('/content/drive/MyDrive/Dataset Proyek Akhir/DATASETMIX.zip').extractall('/content/')\n","\n","data_dir = \"/content/rice_leaf_diseases\"\n","\n","model_name = \"resnet100\"\n","num_classes = 3\n","batch_size = 8\n","feature_extract = True\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vs4JvMrICBDg"},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  \n","            else:\n","                model.eval()   \n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    if is_inception and phase == 'train':\n","                        outputs, aux_outputs = model(inputs)\n","                        loss1 = criterion(outputs, labels)\n","                        loss2 = criterion(aux_outputs, labels)\n","                        loss = loss1 + 0.4*loss2\n","                    else:\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double(\n","            ) / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'val':\n","                val_acc_history.append(epoch_acc)\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history\n","\n","def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86,"status":"ok","timestamp":1660650527963,"user":{"displayName":"nabil furqan","userId":"03747923580904763607"},"user_tz":-420},"id":"b8--eVtNCmPY","outputId":"ae72bd8e-6176-4bec-92a0-5572a4623025"},"outputs":[{"name":"stdout","output_type":"stream","text":["Invalid model name, exiting...\n","None\n"]}],"source":["def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n","    model_ft = None\n","    input_size = 0\n","\n","    if model_name == \"resnet34\":\n","        \"\"\" Resnet34\n","        \"\"\"\n","        model_ft = models.resnet34(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","        input_size = 224\n","\n","    elif model_name == \"resnet101\":\n","        \"\"\" Resnet101\n","        \"\"\"\n","        model_ft = models.resnet101(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","        input_size = 224\n","\n","    else:\n","        print(\"Invalid model name, exiting...\")\n","        exit()\n","\n","    return model_ft, input_size\n","\n","model_ft, input_size = initialize_model(\n","    model_name, num_classes, feature_extract, use_pretrained=True)\n","\n","print(model_ft)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82,"status":"ok","timestamp":1660650527965,"user":{"displayName":"nabil furqan","userId":"03747923580904763607"},"user_tz":-420},"id":"3p_Yl8q0DiWs","outputId":"ad7b32d5-da8c-459e-d45e-b8cb03632894"},"outputs":[{"name":"stdout","output_type":"stream","text":["Initializing Datasets and Dataloaders...\n"]}],"source":["data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(input_size),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(input_size),\n","        transforms.CenterCrop(input_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","print(\"Initializing Datasets and Dataloaders...\")\n","\n","image_datasets = {x: datasets.ImageFolder(os.path.join(\n","    data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n","dataloaders_dict = {x: torch.utils.data.DataLoader(\n","    image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","class_names = image_datasets['train'].classes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246},"executionInfo":{"elapsed":80,"status":"error","timestamp":1660650527966,"user":{"displayName":"nabil furqan","userId":"03747923580904763607"},"user_tz":-420},"id":"RMqtWo6aDmEy","outputId":"79e4a662-48c5-436a-e618-1d22b2f7ebe0"},"outputs":[{"ename":"AttributeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-f9b9a1a3662f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Send the model to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Gather the parameters to be optimized/updated in this run. If we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#  finetuning we will be updating all parameters. However, if we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to'"]}],"source":["model_ft = model_ft.to(device)\n","\n","params_to_update = model_ft.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name, param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\", name)\n","else:\n","    for name, param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\", name)\n","\n","optimizer_ft = optim.RMSprop(params_to_update, lr=0.001, momentum=0.9)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uaEeR3EdD5bm"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","\n","model_conv, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft,\n","                             num_epochs=100, is_inception=(model_name == \"inception\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-j3kHI4ojZi"},"outputs":[],"source":["confusion_matrix = torch.zeros(num_classes, num_classes)\n","with torch.no_grad():\n","    for i, (inputs, classes) in enumerate(dataloaders_dict['val']):\n","        inputs = inputs.to(device)\n","        classes = classes.to(device)\n","        outputs = model_ft(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        for t, p in zip(classes.view(-1), preds.view(-1)):\n","                confusion_matrix[t.long(), p.long()] += 1\n","print('\\nConfusion Matrix\\n')\n","print(confusion_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q71Tf1dJ3izn"},"outputs":[],"source":["def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  \n","\n","inputs, classes = next(iter(dataloaders_dict['train']))\n","\n","out = torchvision.utils.make_grid(inputs)\n","\n","imshow(out, title=[class_names[x] for x in classes])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kw-Ado2y16pz"},"outputs":[],"source":["def visualize_model(model, num_images=4):\n","    was_training = model.training\n","    model.eval()\n","    images_so_far = 0\n","    fig = plt.figure()\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders_dict['val']):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for j in range(inputs.size()[0]):\n","                images_so_far += 1\n","                ax = plt.subplot(num_images//2, 2, images_so_far)\n","                ax.axis('off')\n","                ax.set_title(f'predicted: {class_names[preds[j]]}')\n","                imshow(inputs.cpu().data[j])\n","\n","                if images_so_far == num_images:\n","                    model.train(mode=was_training)\n","                    return\n","        model.train(mode=was_training)\n","\n","\n","visualize_model(model_conv)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNlS5GR90EQWSMs3AnCqdzN","collapsed_sections":[],"name":"Resnet.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
